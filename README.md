# Universal Edge AI Container Solution

A containerized, production-ready Edge AI solution optimized for low-powered NVIDIA devices (Jetson Nano, Xavier NX, AGX Xavier). This project provides a comprehensive framework for deploying AI applications at the edge with real-time performance monitoring and optimization.

## Project Structure
```
yolo-realtime/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # Main application entry point
â”‚   â”œâ”€â”€ realtime_detector.py    # Real-time detection implementation
â”‚   â”œâ”€â”€ benchmark_utils.py      # Benchmarking utilities
â”‚   â”œâ”€â”€ monitoring_service.py   # Performance monitoring service
â”‚   â”œâ”€â”€ visualization_service.py # Real-time visualization dashboard
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ performance.py      # Performance monitoring utilities
â”‚       â””â”€â”€ visualization.py    # Visualization utilities
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ detector_config.yaml    # Detection configuration
â”‚   â””â”€â”€ monitoring_config.yaml  # Monitoring configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ test_images/           # Test images for benchmarking
â”œâ”€â”€ models/                     # YOLOv8 model files
â”œâ”€â”€ results/                    # Results and metrics
â””â”€â”€ logs/                      # Application logs
```
## ğŸš€ Key Features

- **Universal Compatibility**: 
  - Supports NVIDIA Jetson platforms (Nano, Xavier NX, AGX Xavier)
  - Compatible with x86_64 platforms with NVIDIA GPUs
  - Cross-platform container deployment

- **Optimized Performance**:
  - GPU memory management optimization
  - CUDA acceleration
  - TensorRT integration
  - Hardware-accelerated video pipeline
  - Efficient resource utilization for edge devices

- **Real-time Monitoring**:
  - GPU utilization tracking
  - Memory usage monitoring
  - Temperature monitoring
  - FPS metrics
  - Power consumption analysis

- **AI Capabilities**:
  - Real-time object detection using YOLOv8
  - Multiple model support (nano, small, medium variants)
  - Configurable confidence thresholds
  - Frame processing optimization
  - Video stream support

## ğŸ› ï¸ Technical Architecture

```
Edge_AI_Container/
â”œâ”€â”€ Docker containerization
â”œâ”€â”€ Real-time monitoring system
â”œâ”€â”€ Performance optimization layer
â”œâ”€â”€ AI inference engine
â””â”€â”€ Hardware acceleration integration
```

## ğŸ’¡ Use Cases

- **Industrial IoT**:
  - Quality control inspection
  - Assembly line monitoring
  - Defect detection

- **Smart Cities**:
  - Traffic monitoring
  - Crowd analysis
  - Security surveillance

- **Retail Analytics**:
  - Customer behavior analysis
  - Inventory tracking
  - Queue monitoring

- **Agriculture**:
  - Crop monitoring
  - Livestock tracking
  - Equipment automation

## ğŸ”§ System Requirements

### Minimum Requirements
- NVIDIA Jetson Nano (4GB)
- JetPack 4.6 or later
- 10W power mode

### Recommended Requirements
- NVIDIA Jetson Xavier NX
- JetPack 5.0 or later
- 15W+ power mode

### Software Requirements
- Docker Engine
- NVIDIA Container Runtime
- CUDA 11.4+
- TensorRT 8.0+

## ğŸ“ˆ Performance Metrics

| Device         | Power Mode | FPS  | GPU Usage | Memory |
|---------------|------------|------|-----------|---------|
| Jetson Nano   | 10W        | 12-15| 80%      | 2.5GB   |
| Xavier NX     | 15W        | 25-30| 70%      | 4GB     |
| AGX Xavier    | 30W        | 45-50| 60%      | 8GB     |

## ğŸŒŸ Features in Detail

### Hardware Optimization
- Dynamic voltage and frequency scaling
- Efficient memory management
- Optimized video encoding/decoding
- Multi-threading optimization

### AI Model Management
- Model quantization support
- TensorRT optimization
- Multiple model loading
- Dynamic model switching

### Monitoring and Debugging
- Real-time performance metrics
- System health monitoring
- Resource utilization tracking
- Alert system for critical events

## ğŸ”„ Workflow

1. **Image Acquisition**
   - Camera input processing
   - Frame optimization
   - Buffer management

2. **AI Processing**
   - Model inference
   - TensorRT acceleration
   - Batch processing

3. **Output Handling**
   - Result visualization
   - Data streaming
   - Storage management

## ğŸš€ Getting Started

```bash
# Clone the repository
git clone https://github.com/FacadedevilEdge_AI_Container.git

# Build the container
docker-compose build

# Run the container
docker-compose up
```

## ğŸ“ Configuration

The system can be configured through YAML files:
- `detector_config.yaml`: AI model settings
- `monitoring_config.yaml`: System monitoring parameters

## ğŸ” Monitoring Interface

Access the monitoring dashboard:
- Real-time metrics
- Performance graphs
- System status
- Resource utilization

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- NVIDIA for Jetson platform
- Ultralytics for YOLOv8
- Open-source community

---

Please visit our [Wiki](wiki-link) for more detailed documentation.
